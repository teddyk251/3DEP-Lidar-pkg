<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>3DEP-Lidar-pkg.src.data_fetcher API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>3DEP-Lidar-pkg.src.data_fetcher</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pdal
import json
import pandas as pd
import sys
import numpy as np
import geopandas as gpd
from shapely.geometry import Polygon, Point

BASE_DATA_URL = &#34;https://s3-us-west-2.amazonaws.com/usgs-lidar-public/&#34;


class DataFetcher():

    &#34;&#34;&#34;Data Fetcher Class which handles all data fetching activites from the AWS dataset.

    Parameters
    ----------
    polygon : Polygon
        Polygon of the area which is being searched for
    epsg : str
        CRS system which the polygon is constructed based on
    region: str, optional
        Region where the specified polygon is located in from the file name folder located in the AWS dataset. If
        not provided the program will search and provide the region if it is in the AWS dataset
    &#34;&#34;&#34;

    def __init__(self, polygon: Polygon, epsg: str, region: str) -&gt; None:
        minx, miny, maxx, maxy = self.get_polygon_bounds(polygon, epsg)
        self.epsg = epsg
        if (region):
            self.region = self.check_region(region)
            self.file_path = BASE_DATA_URL + self.region + &#34;/ept.json&#34;
        else:
            self.region = self.get_region_from_bounds(minx, miny, maxx, maxy)

        self.load_pipeline_template()

    def get_polygon_bounds(self, polygon: Polygon, epsg: str) -&gt; tuple:
        &#34;&#34;&#34;Extracts polygon bounds and assign polygon cropping bounds.

        Parameters
        ----------
        polygon : Polygon
            Polygon object describing the boundary of the location required
        epsg : str
            CRS system on which the polygon is constructed on

        Returns
        -------
        tuple
            Returns bounds of the polygon provided(minx, miny, maxx, maxy)
        &#34;&#34;&#34;
        try:
            grid = gpd.GeoDataFrame([polygon], columns=[&#34;geometry&#34;])
            grid.set_crs(epsg=epsg, inplace=True)

            grid[&#39;geometry&#39;] = grid.geometry.to_crs(epsg=3857)

            minx, miny, maxx, maxy = grid.geometry[0].bounds
            # bounds: ([minx, maxx], [miny, maxy])
            self.extraction_bounds = f&#34;({[minx, maxx]},{[miny,maxy]})&#34;

            # Cropping Bounds
            self.polygon_cropping = self.get_crop_polygon(grid.geometry[0])

            grid[&#39;geometry&#39;] = grid.geometry.to_crs(epsg=epsg)
            self.geo_df = grid

            # logger.info(
            #     &#39;Successfully Extracted Polygon Edges and Polygon Cropping Bounds&#39;)

            return minx, miny, maxx, maxy

        except Exception as e:
            print(e)

    def get_crop_polygon(self, polygon: Polygon) -&gt; str:
        &#34;&#34;&#34;Calculates Polygons Cropping string used when building Pdal&#39;s crop pipeline.

        Parameters
        ----------
        polygon: Polygon
            Polygon object describing the boundary of the location required

        Returns
        -------
        str
            Cropping string used by Pdal&#39;s crop pipeline
        &#34;&#34;&#34;
        polygon_cords = &#39;POLYGON((&#39;
        for i in list(polygon.exterior.coords):
            polygon_cords += f&#39;{i[0]} {i[1]},&#39;

        polygon_cords = polygon_cords[:-1] + &#39;))&#39;

        return polygon_cords

    def check_region(self, region: str) -&gt; str:
        &#34;&#34;&#34;Checks if the given region is found in the AWS dataset.

        Parameters
        ----------
        region : str
            Proabable file name of a folder in the AWS dataset

        Returns
        -------
        str
            Returns the same regions folder file name if it was successfully located
        &#34;&#34;&#34;
        with open(&#39;./data/region_list.txt&#39;, &#39;r&#39;) as locations:
            locations_list = []
            for location in locations:
                locations_list.append(location.strip(&#39;\n&#39;).strip(&#39;/&#39;))
        if(region in locations_list):
            return region
        else:
            print(&#34;Region Not Available&#34;)
            sys.exit(1)

    def get_region_from_bounds(self, minx: float, miny: float, maxx: float, maxy: float, indx: int = 1) -&gt; str:
        &#34;&#34;&#34;Searchs for a region which contains the polygon defined from the available boundaries in the AWS 
        dataset.

        Parameters
        ----------
        minx : float
            Minimum longitude value of the polygon
        miny : float
            Minimum latitude value of the polygon
        maxx : float
            Maximum longitude value of the polygon
        maxy : float
            Maximum latitude value of the polygon
        indx : int, optional
            Bound indexing, to select the first or other access url&#39;s of multiple values for a region
        Returns
        -------
        str
            Access url to retrieve the data from the AWS dataset
        &#34;&#34;&#34;

        aws_dataset_info_csv = pd.read_csv(&#39;../data/dataset_metadata.csv&#39;)
        for index, bound in enumerate(aws_dataset_info_csv[&#39;Bound/s&#39;].to_list()):
            bound = bound.strip(&#39;][&#39;).replace(
                &#39;]&#39;, &#39;&#39;).replace(&#39;[&#39;, &#39;&#39;).split(&#39;,&#39;)
            bound = list(map(float, bound))

            bminx, bminy, bmaxx, bmaxy = bound[0 * indx], bound[1 *
                                                                indx], bound[3 * indx], bound[4 * indx]

            if((minx &gt;= bminx and maxx &lt;= bmaxx) and (miny &gt;= bminy and maxy &lt;= bmaxy)):
                access_url = aws_dataset_info_csv[&#39;Access Url/s&#39;].to_list()[
                    index][2:-2]

                region = aws_dataset_info_csv[&#39;Region/s&#39;].to_list()[
                    index] + &#39;_&#39; + aws_dataset_info_csv[&#39;Year/s&#39;].to_list()[index][2:-2]

                print(f&#39;Region found in {region} folder&#39;)
                # logger.info(f&#39;Region found in {region} folder&#39;)

                return access_url
        else:
            print(&#39;Region Not Available&#39;)
            # logger.error(&#39;Region Not Available&#39;)
            sys.exit()

    def load_pipeline_template(self, file_name: str = &#39;./data/pipeline_template.json&#39;) -&gt; None:
        &#34;&#34;&#34;Loads Pipeline Template to constructe Pdal Pipelines from.

        Parameters
        ----------
        file_name : str, optional
            Path plus file name of the pipeline template if the template is not located in its normal locations,
            or if another template file is needed to be loaded

        Returns
        -------
        None
        &#34;&#34;&#34;
        try:
            with open(file_name, &#39;r&#39;) as read_file:
                template = json.load(read_file)

            self.template_pipeline = template

            print(&#39;Pipeline Template loaded successfully&#39;)
            # logger.info(&#39;Successfully Loaded Pdal Pipeline Template&#39;)

        except Exception as e:
            print(&#39;Failed to Load Pipeline Template&#39;)
            # logger.exception(&#39;Failed to Load Pdal Pipeline Template&#39;)
            sys.exit(1)

    def build_pipeline(self) -&gt; None:
        &#34;&#34;&#34;Generates a generic Pdal pipeline.

        Parameters
        ----------
        None

        Returns
        -------
        None
        &#34;&#34;&#34;
        self.pipeline = []
        reader = self.template_pipeline[&#39;reader&#39;]
        reader[&#39;bounds&#39;] = self.extraction_bounds
        reader[&#39;filename&#39;] = self.file_path
        self.pipeline.append(reader)

        cropper = self.template_pipeline[&#39;cropping_filter&#39;]
        cropper[&#39;polygon&#39;] = self.polygon_cropping
        self.pipeline.append(cropper)

        self.pipeline.append(self.template_pipeline[&#39;range_filter&#39;])
        self.pipeline.append(self.template_pipeline[&#39;assign_filter&#39;])

        reprojection = self.template_pipeline[&#39;reprojection_filter&#39;]
        reprojection[&#39;out_srs&#39;] = f&#34;EPSG:{self.epsg}&#34;
        self.pipeline.append(reprojection)

        self.pipeline = pdal.Pipeline(json.dumps(self.pipeline))

    def create_cloud_points(self):
        &#34;&#34;&#34;Creates Cloud Points from the retrieved Pipeline Arrays consisting of other unwanted data.

        Parameters
        ----------
        None

        Returns
        -------
        None
        &#34;&#34;&#34;
        try:
            cloud_points = []
            for row in self.pipeline.arrays[0]:
                lst = row.tolist()[-3:]
                cloud_points.append(lst)

            cloud_points = np.array(cloud_points)

            self.cloud_points = cloud_points

        except:
            print(&#39;Failed to create cloud points&#39;)
            sys.exit(1)

    def get_elevation_geodf(self) -&gt; gpd.GeoDataFrame:
        &#34;&#34;&#34;Calculates and returns a geopandas elevation dataframe from the cloud points generated before.

        Parameters
        ----------
        None

        Returns
        -------
        gpd.GeoDataFrame
            Geopandas Dataframe with Elevation and coordinate points referenced as Geometry points
        &#34;&#34;&#34;
        elevation = gpd.GeoDataFrame()
        elevations = []
        points = []
        for row in self.cloud_points:
            elevations.append(row[2])
            point = Point(row[0], row[1])
            points.append(point)

        elevation[&#39;elevation&#39;] = elevations
        elevation[&#39;geometry&#39;] = points
        elevation.set_crs(epsg=self.epsg, inplace=True)

        self.elevation_geodf = elevation

        return self.elevation_geodf

    def fetch_data(self):
        &#34;&#34;&#34;Fetches Data from the AWS Dataset, builds the cloud points from it and 
        assignes and stores the original cloud points and original elevation geopandas dataframe.

        Parameters
        ----------
        None

        Returns
        -------
        None
        &#34;&#34;&#34;
        try:
            self.build_pipeline()
            self.data_count = self.pipeline.execute()
            self.create_cloud_points()
            self.original_cloud_points = self.cloud_points
            self.original_elevation_geodf = self.get_elevation_geodf()
        except Exception as e:
            sys.exit(1)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher"><code class="flex name class">
<span>class <span class="ident">DataFetcher</span></span>
<span>(</span><span>polygon: shapely.geometry.polygon.Polygon, epsg: str, region: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Data Fetcher Class which handles all data fetching activites from the AWS dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>polygon</code></strong> :&ensp;<code>Polygon</code></dt>
<dd>Polygon of the area which is being searched for</dd>
<dt><strong><code>epsg</code></strong> :&ensp;<code>str</code></dt>
<dd>CRS system which the polygon is constructed based on</dd>
<dt><strong><code>region</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Region where the specified polygon is located in from the file name folder located in the AWS dataset. If
not provided the program will search and provide the region if it is in the AWS dataset</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataFetcher():

    &#34;&#34;&#34;Data Fetcher Class which handles all data fetching activites from the AWS dataset.

    Parameters
    ----------
    polygon : Polygon
        Polygon of the area which is being searched for
    epsg : str
        CRS system which the polygon is constructed based on
    region: str, optional
        Region where the specified polygon is located in from the file name folder located in the AWS dataset. If
        not provided the program will search and provide the region if it is in the AWS dataset
    &#34;&#34;&#34;

    def __init__(self, polygon: Polygon, epsg: str, region: str) -&gt; None:
        minx, miny, maxx, maxy = self.get_polygon_bounds(polygon, epsg)
        self.epsg = epsg
        if (region):
            self.region = self.check_region(region)
            self.file_path = BASE_DATA_URL + self.region + &#34;/ept.json&#34;
        else:
            self.region = self.get_region_from_bounds(minx, miny, maxx, maxy)

        self.load_pipeline_template()

    def get_polygon_bounds(self, polygon: Polygon, epsg: str) -&gt; tuple:
        &#34;&#34;&#34;Extracts polygon bounds and assign polygon cropping bounds.

        Parameters
        ----------
        polygon : Polygon
            Polygon object describing the boundary of the location required
        epsg : str
            CRS system on which the polygon is constructed on

        Returns
        -------
        tuple
            Returns bounds of the polygon provided(minx, miny, maxx, maxy)
        &#34;&#34;&#34;
        try:
            grid = gpd.GeoDataFrame([polygon], columns=[&#34;geometry&#34;])
            grid.set_crs(epsg=epsg, inplace=True)

            grid[&#39;geometry&#39;] = grid.geometry.to_crs(epsg=3857)

            minx, miny, maxx, maxy = grid.geometry[0].bounds
            # bounds: ([minx, maxx], [miny, maxy])
            self.extraction_bounds = f&#34;({[minx, maxx]},{[miny,maxy]})&#34;

            # Cropping Bounds
            self.polygon_cropping = self.get_crop_polygon(grid.geometry[0])

            grid[&#39;geometry&#39;] = grid.geometry.to_crs(epsg=epsg)
            self.geo_df = grid

            # logger.info(
            #     &#39;Successfully Extracted Polygon Edges and Polygon Cropping Bounds&#39;)

            return minx, miny, maxx, maxy

        except Exception as e:
            print(e)

    def get_crop_polygon(self, polygon: Polygon) -&gt; str:
        &#34;&#34;&#34;Calculates Polygons Cropping string used when building Pdal&#39;s crop pipeline.

        Parameters
        ----------
        polygon: Polygon
            Polygon object describing the boundary of the location required

        Returns
        -------
        str
            Cropping string used by Pdal&#39;s crop pipeline
        &#34;&#34;&#34;
        polygon_cords = &#39;POLYGON((&#39;
        for i in list(polygon.exterior.coords):
            polygon_cords += f&#39;{i[0]} {i[1]},&#39;

        polygon_cords = polygon_cords[:-1] + &#39;))&#39;

        return polygon_cords

    def check_region(self, region: str) -&gt; str:
        &#34;&#34;&#34;Checks if the given region is found in the AWS dataset.

        Parameters
        ----------
        region : str
            Proabable file name of a folder in the AWS dataset

        Returns
        -------
        str
            Returns the same regions folder file name if it was successfully located
        &#34;&#34;&#34;
        with open(&#39;./data/region_list.txt&#39;, &#39;r&#39;) as locations:
            locations_list = []
            for location in locations:
                locations_list.append(location.strip(&#39;\n&#39;).strip(&#39;/&#39;))
        if(region in locations_list):
            return region
        else:
            print(&#34;Region Not Available&#34;)
            sys.exit(1)

    def get_region_from_bounds(self, minx: float, miny: float, maxx: float, maxy: float, indx: int = 1) -&gt; str:
        &#34;&#34;&#34;Searchs for a region which contains the polygon defined from the available boundaries in the AWS 
        dataset.

        Parameters
        ----------
        minx : float
            Minimum longitude value of the polygon
        miny : float
            Minimum latitude value of the polygon
        maxx : float
            Maximum longitude value of the polygon
        maxy : float
            Maximum latitude value of the polygon
        indx : int, optional
            Bound indexing, to select the first or other access url&#39;s of multiple values for a region
        Returns
        -------
        str
            Access url to retrieve the data from the AWS dataset
        &#34;&#34;&#34;

        aws_dataset_info_csv = pd.read_csv(&#39;../data/dataset_metadata.csv&#39;)
        for index, bound in enumerate(aws_dataset_info_csv[&#39;Bound/s&#39;].to_list()):
            bound = bound.strip(&#39;][&#39;).replace(
                &#39;]&#39;, &#39;&#39;).replace(&#39;[&#39;, &#39;&#39;).split(&#39;,&#39;)
            bound = list(map(float, bound))

            bminx, bminy, bmaxx, bmaxy = bound[0 * indx], bound[1 *
                                                                indx], bound[3 * indx], bound[4 * indx]

            if((minx &gt;= bminx and maxx &lt;= bmaxx) and (miny &gt;= bminy and maxy &lt;= bmaxy)):
                access_url = aws_dataset_info_csv[&#39;Access Url/s&#39;].to_list()[
                    index][2:-2]

                region = aws_dataset_info_csv[&#39;Region/s&#39;].to_list()[
                    index] + &#39;_&#39; + aws_dataset_info_csv[&#39;Year/s&#39;].to_list()[index][2:-2]

                print(f&#39;Region found in {region} folder&#39;)
                # logger.info(f&#39;Region found in {region} folder&#39;)

                return access_url
        else:
            print(&#39;Region Not Available&#39;)
            # logger.error(&#39;Region Not Available&#39;)
            sys.exit()

    def load_pipeline_template(self, file_name: str = &#39;./data/pipeline_template.json&#39;) -&gt; None:
        &#34;&#34;&#34;Loads Pipeline Template to constructe Pdal Pipelines from.

        Parameters
        ----------
        file_name : str, optional
            Path plus file name of the pipeline template if the template is not located in its normal locations,
            or if another template file is needed to be loaded

        Returns
        -------
        None
        &#34;&#34;&#34;
        try:
            with open(file_name, &#39;r&#39;) as read_file:
                template = json.load(read_file)

            self.template_pipeline = template

            print(&#39;Pipeline Template loaded successfully&#39;)
            # logger.info(&#39;Successfully Loaded Pdal Pipeline Template&#39;)

        except Exception as e:
            print(&#39;Failed to Load Pipeline Template&#39;)
            # logger.exception(&#39;Failed to Load Pdal Pipeline Template&#39;)
            sys.exit(1)

    def build_pipeline(self) -&gt; None:
        &#34;&#34;&#34;Generates a generic Pdal pipeline.

        Parameters
        ----------
        None

        Returns
        -------
        None
        &#34;&#34;&#34;
        self.pipeline = []
        reader = self.template_pipeline[&#39;reader&#39;]
        reader[&#39;bounds&#39;] = self.extraction_bounds
        reader[&#39;filename&#39;] = self.file_path
        self.pipeline.append(reader)

        cropper = self.template_pipeline[&#39;cropping_filter&#39;]
        cropper[&#39;polygon&#39;] = self.polygon_cropping
        self.pipeline.append(cropper)

        self.pipeline.append(self.template_pipeline[&#39;range_filter&#39;])
        self.pipeline.append(self.template_pipeline[&#39;assign_filter&#39;])

        reprojection = self.template_pipeline[&#39;reprojection_filter&#39;]
        reprojection[&#39;out_srs&#39;] = f&#34;EPSG:{self.epsg}&#34;
        self.pipeline.append(reprojection)

        self.pipeline = pdal.Pipeline(json.dumps(self.pipeline))

    def create_cloud_points(self):
        &#34;&#34;&#34;Creates Cloud Points from the retrieved Pipeline Arrays consisting of other unwanted data.

        Parameters
        ----------
        None

        Returns
        -------
        None
        &#34;&#34;&#34;
        try:
            cloud_points = []
            for row in self.pipeline.arrays[0]:
                lst = row.tolist()[-3:]
                cloud_points.append(lst)

            cloud_points = np.array(cloud_points)

            self.cloud_points = cloud_points

        except:
            print(&#39;Failed to create cloud points&#39;)
            sys.exit(1)

    def get_elevation_geodf(self) -&gt; gpd.GeoDataFrame:
        &#34;&#34;&#34;Calculates and returns a geopandas elevation dataframe from the cloud points generated before.

        Parameters
        ----------
        None

        Returns
        -------
        gpd.GeoDataFrame
            Geopandas Dataframe with Elevation and coordinate points referenced as Geometry points
        &#34;&#34;&#34;
        elevation = gpd.GeoDataFrame()
        elevations = []
        points = []
        for row in self.cloud_points:
            elevations.append(row[2])
            point = Point(row[0], row[1])
            points.append(point)

        elevation[&#39;elevation&#39;] = elevations
        elevation[&#39;geometry&#39;] = points
        elevation.set_crs(epsg=self.epsg, inplace=True)

        self.elevation_geodf = elevation

        return self.elevation_geodf

    def fetch_data(self):
        &#34;&#34;&#34;Fetches Data from the AWS Dataset, builds the cloud points from it and 
        assignes and stores the original cloud points and original elevation geopandas dataframe.

        Parameters
        ----------
        None

        Returns
        -------
        None
        &#34;&#34;&#34;
        try:
            self.build_pipeline()
            self.data_count = self.pipeline.execute()
            self.create_cloud_points()
            self.original_cloud_points = self.cloud_points
            self.original_elevation_geodf = self.get_elevation_geodf()
        except Exception as e:
            sys.exit(1)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.build_pipeline"><code class="name flex">
<span>def <span class="ident">build_pipeline</span></span>(<span>self) ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a generic Pdal pipeline.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build_pipeline(self) -&gt; None:
    &#34;&#34;&#34;Generates a generic Pdal pipeline.

    Parameters
    ----------
    None

    Returns
    -------
    None
    &#34;&#34;&#34;
    self.pipeline = []
    reader = self.template_pipeline[&#39;reader&#39;]
    reader[&#39;bounds&#39;] = self.extraction_bounds
    reader[&#39;filename&#39;] = self.file_path
    self.pipeline.append(reader)

    cropper = self.template_pipeline[&#39;cropping_filter&#39;]
    cropper[&#39;polygon&#39;] = self.polygon_cropping
    self.pipeline.append(cropper)

    self.pipeline.append(self.template_pipeline[&#39;range_filter&#39;])
    self.pipeline.append(self.template_pipeline[&#39;assign_filter&#39;])

    reprojection = self.template_pipeline[&#39;reprojection_filter&#39;]
    reprojection[&#39;out_srs&#39;] = f&#34;EPSG:{self.epsg}&#34;
    self.pipeline.append(reprojection)

    self.pipeline = pdal.Pipeline(json.dumps(self.pipeline))</code></pre>
</details>
</dd>
<dt id="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.check_region"><code class="name flex">
<span>def <span class="ident">check_region</span></span>(<span>self, region: str) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Checks if the given region is found in the AWS dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>region</code></strong> :&ensp;<code>str</code></dt>
<dd>Proabable file name of a folder in the AWS dataset</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Returns the same regions folder file name if it was successfully located</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_region(self, region: str) -&gt; str:
    &#34;&#34;&#34;Checks if the given region is found in the AWS dataset.

    Parameters
    ----------
    region : str
        Proabable file name of a folder in the AWS dataset

    Returns
    -------
    str
        Returns the same regions folder file name if it was successfully located
    &#34;&#34;&#34;
    with open(&#39;./data/region_list.txt&#39;, &#39;r&#39;) as locations:
        locations_list = []
        for location in locations:
            locations_list.append(location.strip(&#39;\n&#39;).strip(&#39;/&#39;))
    if(region in locations_list):
        return region
    else:
        print(&#34;Region Not Available&#34;)
        sys.exit(1)</code></pre>
</details>
</dd>
<dt id="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.create_cloud_points"><code class="name flex">
<span>def <span class="ident">create_cloud_points</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates Cloud Points from the retrieved Pipeline Arrays consisting of other unwanted data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_cloud_points(self):
    &#34;&#34;&#34;Creates Cloud Points from the retrieved Pipeline Arrays consisting of other unwanted data.

    Parameters
    ----------
    None

    Returns
    -------
    None
    &#34;&#34;&#34;
    try:
        cloud_points = []
        for row in self.pipeline.arrays[0]:
            lst = row.tolist()[-3:]
            cloud_points.append(lst)

        cloud_points = np.array(cloud_points)

        self.cloud_points = cloud_points

    except:
        print(&#39;Failed to create cloud points&#39;)
        sys.exit(1)</code></pre>
</details>
</dd>
<dt id="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.fetch_data"><code class="name flex">
<span>def <span class="ident">fetch_data</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Fetches Data from the AWS Dataset, builds the cloud points from it and
assignes and stores the original cloud points and original elevation geopandas dataframe.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fetch_data(self):
    &#34;&#34;&#34;Fetches Data from the AWS Dataset, builds the cloud points from it and 
    assignes and stores the original cloud points and original elevation geopandas dataframe.

    Parameters
    ----------
    None

    Returns
    -------
    None
    &#34;&#34;&#34;
    try:
        self.build_pipeline()
        self.data_count = self.pipeline.execute()
        self.create_cloud_points()
        self.original_cloud_points = self.cloud_points
        self.original_elevation_geodf = self.get_elevation_geodf()
    except Exception as e:
        sys.exit(1)</code></pre>
</details>
</dd>
<dt id="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_crop_polygon"><code class="name flex">
<span>def <span class="ident">get_crop_polygon</span></span>(<span>self, polygon: shapely.geometry.polygon.Polygon) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates Polygons Cropping string used when building Pdal's crop pipeline.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>polygon</code></strong> :&ensp;<code>Polygon</code></dt>
<dd>Polygon object describing the boundary of the location required</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Cropping string used by Pdal's crop pipeline</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_crop_polygon(self, polygon: Polygon) -&gt; str:
    &#34;&#34;&#34;Calculates Polygons Cropping string used when building Pdal&#39;s crop pipeline.

    Parameters
    ----------
    polygon: Polygon
        Polygon object describing the boundary of the location required

    Returns
    -------
    str
        Cropping string used by Pdal&#39;s crop pipeline
    &#34;&#34;&#34;
    polygon_cords = &#39;POLYGON((&#39;
    for i in list(polygon.exterior.coords):
        polygon_cords += f&#39;{i[0]} {i[1]},&#39;

    polygon_cords = polygon_cords[:-1] + &#39;))&#39;

    return polygon_cords</code></pre>
</details>
</dd>
<dt id="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_elevation_geodf"><code class="name flex">
<span>def <span class="ident">get_elevation_geodf</span></span>(<span>self) ‑> geopandas.geodataframe.GeoDataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates and returns a geopandas elevation dataframe from the cloud points generated before.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>gpd.GeoDataFrame</code></dt>
<dd>Geopandas Dataframe with Elevation and coordinate points referenced as Geometry points</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_elevation_geodf(self) -&gt; gpd.GeoDataFrame:
    &#34;&#34;&#34;Calculates and returns a geopandas elevation dataframe from the cloud points generated before.

    Parameters
    ----------
    None

    Returns
    -------
    gpd.GeoDataFrame
        Geopandas Dataframe with Elevation and coordinate points referenced as Geometry points
    &#34;&#34;&#34;
    elevation = gpd.GeoDataFrame()
    elevations = []
    points = []
    for row in self.cloud_points:
        elevations.append(row[2])
        point = Point(row[0], row[1])
        points.append(point)

    elevation[&#39;elevation&#39;] = elevations
    elevation[&#39;geometry&#39;] = points
    elevation.set_crs(epsg=self.epsg, inplace=True)

    self.elevation_geodf = elevation

    return self.elevation_geodf</code></pre>
</details>
</dd>
<dt id="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_polygon_bounds"><code class="name flex">
<span>def <span class="ident">get_polygon_bounds</span></span>(<span>self, polygon: shapely.geometry.polygon.Polygon, epsg: str) ‑> tuple</span>
</code></dt>
<dd>
<div class="desc"><p>Extracts polygon bounds and assign polygon cropping bounds.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>polygon</code></strong> :&ensp;<code>Polygon</code></dt>
<dd>Polygon object describing the boundary of the location required</dd>
<dt><strong><code>epsg</code></strong> :&ensp;<code>str</code></dt>
<dd>CRS system on which the polygon is constructed on</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>tuple</code></dt>
<dd>Returns bounds of the polygon provided(minx, miny, maxx, maxy)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_polygon_bounds(self, polygon: Polygon, epsg: str) -&gt; tuple:
    &#34;&#34;&#34;Extracts polygon bounds and assign polygon cropping bounds.

    Parameters
    ----------
    polygon : Polygon
        Polygon object describing the boundary of the location required
    epsg : str
        CRS system on which the polygon is constructed on

    Returns
    -------
    tuple
        Returns bounds of the polygon provided(minx, miny, maxx, maxy)
    &#34;&#34;&#34;
    try:
        grid = gpd.GeoDataFrame([polygon], columns=[&#34;geometry&#34;])
        grid.set_crs(epsg=epsg, inplace=True)

        grid[&#39;geometry&#39;] = grid.geometry.to_crs(epsg=3857)

        minx, miny, maxx, maxy = grid.geometry[0].bounds
        # bounds: ([minx, maxx], [miny, maxy])
        self.extraction_bounds = f&#34;({[minx, maxx]},{[miny,maxy]})&#34;

        # Cropping Bounds
        self.polygon_cropping = self.get_crop_polygon(grid.geometry[0])

        grid[&#39;geometry&#39;] = grid.geometry.to_crs(epsg=epsg)
        self.geo_df = grid

        # logger.info(
        #     &#39;Successfully Extracted Polygon Edges and Polygon Cropping Bounds&#39;)

        return minx, miny, maxx, maxy

    except Exception as e:
        print(e)</code></pre>
</details>
</dd>
<dt id="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_region_from_bounds"><code class="name flex">
<span>def <span class="ident">get_region_from_bounds</span></span>(<span>self, minx: float, miny: float, maxx: float, maxy: float, indx: int = 1) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Searchs for a region which contains the polygon defined from the available boundaries in the AWS
dataset.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>minx</code></strong> :&ensp;<code>float</code></dt>
<dd>Minimum longitude value of the polygon</dd>
<dt><strong><code>miny</code></strong> :&ensp;<code>float</code></dt>
<dd>Minimum latitude value of the polygon</dd>
<dt><strong><code>maxx</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum longitude value of the polygon</dd>
<dt><strong><code>maxy</code></strong> :&ensp;<code>float</code></dt>
<dd>Maximum latitude value of the polygon</dd>
<dt><strong><code>indx</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Bound indexing, to select the first or other access url's of multiple values for a region</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>Access url to retrieve the data from the AWS dataset</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_region_from_bounds(self, minx: float, miny: float, maxx: float, maxy: float, indx: int = 1) -&gt; str:
    &#34;&#34;&#34;Searchs for a region which contains the polygon defined from the available boundaries in the AWS 
    dataset.

    Parameters
    ----------
    minx : float
        Minimum longitude value of the polygon
    miny : float
        Minimum latitude value of the polygon
    maxx : float
        Maximum longitude value of the polygon
    maxy : float
        Maximum latitude value of the polygon
    indx : int, optional
        Bound indexing, to select the first or other access url&#39;s of multiple values for a region
    Returns
    -------
    str
        Access url to retrieve the data from the AWS dataset
    &#34;&#34;&#34;

    aws_dataset_info_csv = pd.read_csv(&#39;../data/dataset_metadata.csv&#39;)
    for index, bound in enumerate(aws_dataset_info_csv[&#39;Bound/s&#39;].to_list()):
        bound = bound.strip(&#39;][&#39;).replace(
            &#39;]&#39;, &#39;&#39;).replace(&#39;[&#39;, &#39;&#39;).split(&#39;,&#39;)
        bound = list(map(float, bound))

        bminx, bminy, bmaxx, bmaxy = bound[0 * indx], bound[1 *
                                                            indx], bound[3 * indx], bound[4 * indx]

        if((minx &gt;= bminx and maxx &lt;= bmaxx) and (miny &gt;= bminy and maxy &lt;= bmaxy)):
            access_url = aws_dataset_info_csv[&#39;Access Url/s&#39;].to_list()[
                index][2:-2]

            region = aws_dataset_info_csv[&#39;Region/s&#39;].to_list()[
                index] + &#39;_&#39; + aws_dataset_info_csv[&#39;Year/s&#39;].to_list()[index][2:-2]

            print(f&#39;Region found in {region} folder&#39;)
            # logger.info(f&#39;Region found in {region} folder&#39;)

            return access_url
    else:
        print(&#39;Region Not Available&#39;)
        # logger.error(&#39;Region Not Available&#39;)
        sys.exit()</code></pre>
</details>
</dd>
<dt id="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.load_pipeline_template"><code class="name flex">
<span>def <span class="ident">load_pipeline_template</span></span>(<span>self, file_name: str = './data/pipeline_template.json') ‑> None</span>
</code></dt>
<dd>
<div class="desc"><p>Loads Pipeline Template to constructe Pdal Pipelines from.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>file_name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Path plus file name of the pipeline template if the template is not located in its normal locations,
or if another template file is needed to be loaded</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_pipeline_template(self, file_name: str = &#39;./data/pipeline_template.json&#39;) -&gt; None:
    &#34;&#34;&#34;Loads Pipeline Template to constructe Pdal Pipelines from.

    Parameters
    ----------
    file_name : str, optional
        Path plus file name of the pipeline template if the template is not located in its normal locations,
        or if another template file is needed to be loaded

    Returns
    -------
    None
    &#34;&#34;&#34;
    try:
        with open(file_name, &#39;r&#39;) as read_file:
            template = json.load(read_file)

        self.template_pipeline = template

        print(&#39;Pipeline Template loaded successfully&#39;)
        # logger.info(&#39;Successfully Loaded Pdal Pipeline Template&#39;)

    except Exception as e:
        print(&#39;Failed to Load Pipeline Template&#39;)
        # logger.exception(&#39;Failed to Load Pdal Pipeline Template&#39;)
        sys.exit(1)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="3DEP-Lidar-pkg.src" href="index.html">3DEP-Lidar-pkg.src</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher" href="#3DEP-Lidar-pkg.src.data_fetcher.DataFetcher">DataFetcher</a></code></h4>
<ul class="">
<li><code><a title="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.build_pipeline" href="#3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.build_pipeline">build_pipeline</a></code></li>
<li><code><a title="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.check_region" href="#3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.check_region">check_region</a></code></li>
<li><code><a title="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.create_cloud_points" href="#3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.create_cloud_points">create_cloud_points</a></code></li>
<li><code><a title="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.fetch_data" href="#3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.fetch_data">fetch_data</a></code></li>
<li><code><a title="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_crop_polygon" href="#3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_crop_polygon">get_crop_polygon</a></code></li>
<li><code><a title="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_elevation_geodf" href="#3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_elevation_geodf">get_elevation_geodf</a></code></li>
<li><code><a title="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_polygon_bounds" href="#3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_polygon_bounds">get_polygon_bounds</a></code></li>
<li><code><a title="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_region_from_bounds" href="#3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.get_region_from_bounds">get_region_from_bounds</a></code></li>
<li><code><a title="3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.load_pipeline_template" href="#3DEP-Lidar-pkg.src.data_fetcher.DataFetcher.load_pipeline_template">load_pipeline_template</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>